Re-architecting hyperscript.org: A Blueprint for a Compiler-First, Modular Runtime Infrastructure
Executive Summary
This report presents a strategic and technical blueprint to evolve hyperscript.org from its current state as a runtime-interpreted library into a high-performance, compiler-first framework. The central proposal is the introduction of a build-time compilation process that statically analyzes hyperscript code embedded within HTML attributes and generates highly optimized, tree-shaken JavaScript modules. This architectural transformation is designed to address the inherent performance limitations of the current model while preserving the core philosophical strengths that define hyperscript: its readable, declarative syntax and the principle of Locality of Behaviour.
The proposed architectural shift will deliver three primary benefits. First, it will enable minimal bundle sizes. By statically analyzing which hyperscript commands and expressions are utilized on a page, the compiler will ensure that the final client-side bundle includes only the necessary runtime code, drastically reducing the payload from its current monolithic size. Second, it will yield superior runtime performance. Pre-compiling the declarative hyperscript syntax into imperative, Just-In-Time (JIT) friendly JavaScript eliminates all runtime parsing overhead. This unlocks a new tier of performance by allowing modern JavaScript engines like V8 to apply aggressive optimizations that are impossible in the current interpretive model. Third, this initiative will result in a modernized and maintainable codebase. Transitioning the project to a fully modular TypeScript monorepo will introduce robust type safety, significantly improve the developer contribution experience, and establish a stable foundation for the future evolution of the hyperscript language.
The path forward involves the development of two principal components: a Hyperscript Compiler and a Modular Runtime Library. The implementation will be executed in distinct phases, commencing with the foundational refactoring of the runtime into a tree-shakable TypeScript library. This will be followed by the development of the compiler's core logic and culminate in the release of the compiler itself, along with associated developer tooling such as a Command-Line Interface (CLI) and a Vite plugin. This evolution will not only solve the technical challenges of the modern web but also position hyperscript as a leading framework in the minimalist, performance-focused ecosystem, retaining its beloved syntax while embracing state-of-the-art engineering principles.
Deconstructing the Current hyperscript.org Paradigm
Philosophical Strengths: Simplicity and Locality of Behaviour
The enduring appeal of hyperscript.org stems from a clear and compelling philosophy that prioritizes developer experience and code readability. It is designed as an approachable, event-driven scripting language explicitly for modern web front-ends, allowing developers to manage DOM manipulation and respond to events with remarkable clarity.
At the heart of this philosophy is the principle of Locality of Behaviour (LoB). Unlike traditional JavaScript development which often necessitates separate files and complex module imports to attach behavior to DOM elements, hyperscript encourages developers to place logic directly on the element it affects. This is accomplished through the _ (underscore) attribute, which serves as the container for hyperscript code. This co-location of markup and behavior makes components easier to understand, maintain, and reason about, as the entirety of an element's functionality is defined in one place. This approach stands in stark contrast to frameworks that enforce a strict separation of concerns, which can sometimes lead to a fragmented developer experience where logic is scattered across multiple files and directories. The new architecture must treat this principle as a primary design constraint, ensuring that the developer experience of writing code directly in HTML is not only preserved but enhanced.
Furthermore, hyperscript's syntax is a deliberate departure from conventional programming languages, drawing its lineage from the xTalk family of languages, which includes HyperTalk and AppleScript. This heritage informs its core design goal: to favor read time over write time. The resulting syntax is highly expressive and reads like terse, natural-language documentation. Commands such as on click toggle.red on me are immediately intelligible, reducing the cognitive load on developers returning to the code and making it more accessible to those less familiar with complex JavaScript idioms. This focus on readability is a defining characteristic that will directly influence the design of the proposed compiler's parser and Abstract Syntax Tree (AST).
Architectural Analysis of the Current Runtime Model
The current implementation of hyperscript.org is a direct reflection of its philosophy of simplicity: it is a dependency-free, monolithic JavaScript library designed to be included on a web page via a single <script> tag, requiring no build step. This "drop-in" nature is a significant factor in its adoption, particularly within the htmx community, where it serves as a client-side companion for interactions that do not require a server roundtrip.
The runtime initialization process begins with a call to _hyperscript.browserInit(), which scans the entire DOM for elements containing the _ attribute. For each such element, the runtime parses the attribute's string content and executes the described logic. This model extends to dynamic content; if new HTML is added to the page via AJAX or other client-side scripts, a manual call to _hyperscript.processNode(newContent) is required to make the hyperscript on the new elements active. This highlights a fundamental characteristic of the architecture: all parsing, interpretation, and execution logic is handled entirely at runtime, within the user's browser.
This architectural choice has a profound consequence: the entire library, which encompasses a rich set of features, commands, and expressions, must be loaded by the client. A comprehensive list of these features includes dozens of commands like add, fetch, if, repeat, and transition, as well as a wide array of expressions for DOM querying, logical operations, and value conversions. Regardless of whether a page uses a single on click toggle.red or the full suite of asynchronous and control flow commands, the entire runtime is downloaded and parsed by the browser. A comparative analysis with the Elm language showed the current minified and gzipped runtime to be 24KB, a non-trivial payload for applications aiming for minimal footprint and optimal load times. This monolithic nature represents the most significant architectural liability in the context of modern web performance standards.
Identifying the Performance Ceiling and Architectural Limitations
While the current runtime model successfully delivers on its promise of simplicity, it imposes a hard ceiling on performance and introduces architectural limitations that hinder its potential. These limitations can be categorized into three main areas.
First is the monolithic bundle problem. The all-or-nothing delivery of the library is fundamentally at odds with modern web development best practices, which emphasize sending only the code necessary for the current view to function. This is the primary driver for the proposed architectural shift. As web performance becomes increasingly critical, forcing users to download code for features like eventsource or transition when they are only using a simple toggle command is no longer a tenable trade-off.
Second is the significant runtime parsing overhead. The current process involves multiple layers of interpretation. The browser's JavaScript engine must first parse and execute the entire hyperscript.org library. Then, the hyperscript runtime must traverse the DOM, find all _ attributes, and parse the string content of each one. Only after this multi-step process can the actual logic be executed. This overhead is paid on initial page load for all elements and is incurred again every time processNode is called for dynamic content. This introduces a tangible latency to user interactions that could be entirely eliminated by a build-time compilation step.
Third is the complete lack of static optimization opportunities. Because the logic exists only as strings in HTML attributes until runtime, it is impossible to perform any static analysis. The system cannot know ahead of time which features will be used, what variables are in scope, or how to optimize sequences of DOM interactions. This prevents the application of powerful optimization techniques that have become standard in modern JavaScript frameworks, such as dead code elimination (tree-shaking), scope hoisting, and the fusion of multiple operations into a single, more efficient one. Furthermore, this runtime-only nature affects reliability; syntax errors or logical mistakes in a hyperscript string are only discovered when a user performs an action, leading to runtime exceptions. A compiler, by contrast, can detect and report these errors at build time, leading to a more robust and predictable development process.
The fundamental conflict within hyperscript is between its philosophical goal of simplicity, exemplified by the "no build step" approach, and the technical imperatives of the modern web, which demand build-time optimization for performance. The current architecture prioritizes the former at the direct expense of the latter. A successful re-architecture must resolve this tension. It cannot simply impose a complex build process on a user base that values simplicity. Instead, the new compiler and its associated tooling must be designed with such a seamless and "zero-config" developer experience that it feels as if there is no build step. By integrating transparently with popular tools like Vite or offering a standalone CLI that works out of the box, the new infrastructure can deliver the profound performance benefits of a compiler without sacrificing the elegant simplicity that is hyperscript's greatest strength.
Architectural Blueprints from Modern JavaScript Compilers
The "Compiler as Framework" Paradigm Shift
The modern front-end landscape has seen a significant architectural evolution, moving away from monolithic runtime libraries towards a "compiler as framework" paradigm. This shift, pioneered and popularized by frameworks like Svelte, SolidJS, and Qwik, is founded on the principle of moving as much computational work as possible from the user's browser at runtime to a build step at compile time. The core objective is to take a high-level, declarative syntax that is optimized for developer experience and compile it down to low-level, imperative JavaScript that is optimized for machine execution. This approach fundamentally changes the role of the framework: it becomes a language toolchain rather than just a client-side library. The result is a smaller client-side footprint, faster execution, and a more efficient use of resources, as the browser is served only the minimal, specific code required to render and manage the UI. This paradigm provides the foundational blueprint for re-architecting hyperscript.org.
Svelte: The "Disappearing Framework" Model
Svelte exemplifies the "disappearing framework" concept. It is not a runtime library in the traditional sense, but rather a compiler that ingests .svelte files—which contain standard HTML, CSS, and JavaScript—and outputs a small, efficient, and self-contained JavaScript module.
The Svelte compilation pipeline follows a classic three-stage process: Parse, Analyze, and Transform.
 * Parsing: The compiler first deconstructs the .svelte file into its constituent parts, creating separate Abstract Syntax Trees (ASTs) for the HTML markup, CSS styles, and JavaScript logic. It leverages established tools like acorn for JavaScript and css-tree for CSS to build these structured representations.
 * Analysis: With the ASTs in hand, the compiler's analyzer traverses these trees to understand the component's structure and behavior. It identifies reactive dependencies—for instance, noting that a change to a variable count requires an update to a specific text node in the DOM. It also maps out component props, event handlers, and style scopes.
 * Code Generation: In the final stage, the compiler generates highly optimized, imperative JavaScript code. Crucially, Svelte does not use a Virtual DOM. Instead, the generated code directly manipulates the DOM with precise instructions like element.textContent = value or element.classList.add('active'). This surgical approach avoids the overhead of VDOM diffing and results in exceptionally fast updates.
The Svelte model is directly relevant to the future of hyperscript. It provides a proven blueprint for compiling a domain-specific language (Svelte's extended HTML) embedded within a host language (HTML) into optimized, vanilla JavaScript. The proposed hyperscript compiler can adapt this pipeline, treating the content of the _ attribute as its source code, parsing it into a hyperscript-specific AST, analyzing its dependencies, and generating efficient, imperative JavaScript.
SolidJS: Fine-Grained Reactivity and the "Vanishing Component"
SolidJS offers another powerful example of a compiler-driven architecture, implemented as a Babel plugin that transforms JSX into highly efficient code. Its design is centered around two key concepts: fine-grained reactivity and vanishing components.
 * Fine-Grained Reactivity: Solid's performance comes from its incredibly precise update model. Instead of re-rendering entire components when state changes, Solid's reactive system—built on a foundation of primitives called Signals, Memos, and Effects—updates only the specific DOM nodes that are directly subscribed to a piece of state. If a signal's value changes, only the text nodes or attributes that use that signal are re-evaluated, leaving the rest of the DOM untouched.
 * Vanishing Components: In Solid, components are merely functions that execute once during the initial render. Their purpose is to organize code and set up the view and the reactive graph. They do not persist as objects or closures at runtime, which completely eliminates the overhead associated with component instances, lifecycles, and VDOM trees.
The architecture of SolidJS provides valuable lessons for hyperscript. Although hyperscript is not component-based in the same vein, its event-driven nature can be compiled into a similar reactive graph. An on click event can be seen as the trigger, and the subsequent commands that manipulate the DOM are the effects. The compiler can analyze a hyperscript string and generate a reactive graph where events trigger surgical updates to the precise DOM elements identified by hyperscript's powerful query syntax. This approach would be far more efficient than the current model of re-evaluating the script on each event.
Qwik: The Frontier of Performance with Resumability
Qwik represents the most radical implementation of the compiler-first philosophy, aiming for a near-instant time-to-interactive, or what it terms O(1) constant time, by completely eliminating the concept of hydration.
 * Resumability: Instead of re-executing application code on the client to attach event listeners and build up state (hydration), Qwik "resumes" the application from where the server left off. It achieves this by serializing the entire application state, component hierarchy, and event listener locations directly into the HTML sent to the browser.
 * The Optimizer: The core of this technology is the Qwik Optimizer, a build-time tool written in Rust for maximum performance. The Optimizer performs a sophisticated code transformation called "closure extraction." It scans the code for a special marker ($), such as in an event handler like onClick$, and extracts that function (and its closed-over state) into a separate, tiny JavaScript chunk that can be lazy-loaded on demand. This breaks the application into potentially thousands of micro-chunks, ensuring that the browser only ever downloads the code for the specific interaction the user is performing at that exact moment.
While implementing full resumability is likely beyond the scope and contrary to the philosophy of simplicity for hyperscript, Qwik's architecture offers a profound lesson. The Optimizer is a powerful demonstration of how a build-time tool can fundamentally restructure code to achieve unprecedented levels of performance. It validates the use of a high-performance language like Rust for the compiler toolchain and showcases the ultimate logical conclusion of lazy loading: only ship the code for the action the user is taking right now.
The common thread connecting Svelte, SolidJS, and Qwik is the presence of a powerful, purpose-built static analyzer that is intimately aware of the framework's unique semantics. Svelte's analyzer understands that a variable assignment can trigger a DOM update. Solid's analyzer understands how to convert JSX into a graph of reactive signals. Qwik's analyzer understands how to use the $ marker to extract closures. For hyperscript to achieve similar gains, it must adopt this same principle. The new architecture cannot rely on generic tooling alone; it must be built around a static analyzer that deeply understands the hyperscript language itself—its commands like fetch and toggle, its implicit variables me and it, its control flow with then, and its DOM targeting expressions. This custom-built intelligence is the essential ingredient that will unlock the full potential of a compiled hyperscript.
Comparative Analysis of Compiler Frameworks
To contextualize the architectural choices for hyperscript, it is useful to compare these modern frameworks across several key dimensions.
| Feature | Svelte | SolidJS | Qwik |
|---|---|---|---|
| Performance Model | No Virtual DOM; surgical DOM updates compiled from reactive assignments. | Fine-Grained Reactivity via Signals; no Virtual DOM; "vanishing" components. | Resumability; no hydration; O(1) Time To Interactive. |
| Compilation Strategy | Custom compiler for .svelte files; transforms to imperative JavaScript. | Babel plugin transforms JSX into optimized DOM creation and reactive bindings. | Rust-based "Optimizer" performs closure extraction and aggressive code splitting. |
| Runtime Size | Minimal runtime functions are imported as needed by compiled components. | Tiny reactive core library (~7KB) is required on the client. | Micro-loader (~1KB) manages lazy-loading of all other application code. |
| Key Trade-offs | Requires learning a new .svelte file format (HTML with extensions). | Requires adherence to reactivity rules (e.g., no prop destructuring). | Requires a new mental model ("resumable") and serialization constraints on state. |
This comparison reveals a spectrum of "compiler-ness," from Solid's enhancement of a familiar syntax (JSX) to Svelte's creation of a new file format, to Qwik's radical restructuring of the execution model. Hyperscript is best positioned to adopt an architecture analogous to Svelte's. It already possesses a custom syntax designed to be embedded within a host language (HTML). The most logical and effective path forward is to treat the content of the _ attribute as Svelte treats its <script> and markup blocks: as source code for a dedicated compiler that generates a standalone, optimized JavaScript module.
Proposed Architecture: The hyperscript Compiler and Modular Runtime
Core Philosophy: From Runtime Interpreter to Build-Time Compiler
The proposed architecture represents a fundamental strategic shift for hyperscript.org. The project will evolve from being a runtime library to being a language with a dedicated compiler toolchain. In this new paradigm, the runtime library is no longer the primary product delivered to the user; it becomes the compilation target—a standard library of functions that the compiler can draw upon.
The developer experience remains paramount. The complexity of this build process will be abstracted away behind a "zero-config" toolchain. This tool will integrate seamlessly into popular, existing development environments like Vite or function as a standalone Command-Line Interface (CLI). In either mode, its operation will be straightforward: it will scan a project's HTML files, discover all _ attributes, compile their contents, and output a single, optimized JavaScript bundle containing only the necessary runtime code. This preserves the feeling of simplicity while delivering the performance of a modern compiled framework.
The TypeScript Monorepo Structure
To support this new architecture and foster a modern, maintainable codebase, the project will be restructured into a TypeScript monorepo, managed with a tool such as pnpm workspaces. This structure provides clear separation of concerns and simplifies dependency management across the various components of the toolchain, a practice common in modern library development.
The monorepo will consist of the following distinct packages:
 * @hyperscript/compiler: This package will house the core compiler. For maximum performance, it is recommended to be written in a systems language like Rust, which can be compiled to a native binary for the CLI and to WebAssembly (WASM) for in-browser or Node.js environments, drawing inspiration from the high-performance Qwik Optimizer. An alternative is to implement it in TypeScript and leverage esbuild's high-speed transformation APIs, which would lower the barrier for community contributions. This package will contain the parser, static analyzer, and code generator.
 * @hyperscript/runtime: This will be the new, fully modular, and tree-shakable implementation of all hyperscript language features. Written in TypeScript, it will serve as the "standard library" that the compiler targets.
 * @hyperscript/core: A minimal, non-removable core runtime library, estimated to be ~1KB. This package will handle the absolute essential logic required in every hyperscript application, such as the event delegation system and the command execution queue.
 * @hyperscript/cli: A user-friendly command-line interface that provides access to the compiler for users who are not using an integrated build tool like Vite.
 * @hyperscript/vite-plugin: A plugin to provide a seamless, out-of-the-box experience for the large and growing community of developers using Vite.
The Compilation Pipeline: A Deep Dive
The compilation process will transform the declarative hyperscript strings into efficient, imperative JavaScript modules through a three-phase pipeline, analogous to the Svelte compiler's process.
Phase 1: Parsing
The first phase involves parsing the string content of the _ attributes. The parser will be custom-built to understand the unique grammar and syntax of the hyperscript language. It will tokenize the string and construct a hyperscript-specific Abstract Syntax Tree (AST). This AST will be a structured, hierarchical representation of the code, turning a flat string like on click toggle.red into a tree of nodes representing the event handler feature, the toggle command, and its class reference expression.
Phase 2: Static Analysis & Dependency Graphing
This is the most critical phase, where the compiler's "intelligence" resides. A static analyzer will traverse the AST generated in the previous phase. As it visits each node, it will:
 * Identify every command (toggle, fetch, add), expression (.class, #id, me), and feature (on, behavior) used in the script.
 * Resolve implicit targets like me and it to their explicit context.
 * Build a dependency graph that maps each feature in the hyperscript code to a specific, importable function from the @hyperscript/runtime package. For instance, encountering a toggle command node in the AST will add a dependency on the toggleClass function from the runtime library.
Phase 3: Code Generation
In the final phase, the compiler will walk the analyzed AST and generate an optimized, tree-shakable JavaScript module. This generated code will be explicit, imperative, and easy for modern JavaScript engines to optimize.
For example, consider the following input:
 * Input HTML: <button _="on click toggle.red on me wait 1s then add.blue">
The compiler would generate a JavaScript module conceptually similar to this:
 * Output JavaScript (Conceptual):
   import { on, query, toggleClass, wait, addClass } from '@hyperscript/runtime';
import { h_core } from '@hyperscript/core';

// The core runtime would find the target element and invoke this exported function.
export default function(element) {
  on(element, 'click', async () => {
    // The 'me' expression is resolved to the 'element' variable.
    const target = query(element, 'me'); 
    toggleClass(target, 'red');
    await wait(1000); // Hyperscript's implicit async is converted to explicit async/await.
    addClass(target, 'blue');
  });
}

This output is fundamentally different from the current model. It is standard JavaScript, uses async/await to handle hyperscript's transparent asynchronous behavior , and, most importantly, it contains explicit import statements for only the runtime functions it actually needs. This makes it perfectly suited for tree-shaking by a downstream bundler.
The compiler can also perform semantic optimizations based on its deep understanding of the hyperscript language. For instance, a command chain like add.a then remove.b then toggle.c would, in the current runtime, result in three separate DOM manipulations. The new compiler, having a complete AST of the entire command sequence, can analyze this pattern. The code generator could then fuse these operations into a single, more efficient call to a hypothetical runtime function like runtime.batchClassUpdates(element, { add: ['a'], remove: ['b'], toggle: ['c'] }). This reduces layout thrashing and improves rendering performance, an optimization that is simply impossible without a build-time static analysis step.
The Modular Runtime Library
The foundation of this entire architecture is the new @hyperscript/runtime library. It will be rewritten from the ground up in TypeScript as a collection of small, pure, and individually exported functions. This granular, modular design is the essential prerequisite for effective tree-shaking.
Each command, expression, and feature documented by hyperscript.org  will correspond to one or more exported functions within a well-structured directory inside the @hyperscript/runtime package. For example:
 * File: @hyperscript/runtime/commands/toggle.ts
   /**
 * Toggles a CSS class on a given element.
 * This function is pure and has no side effects.
 */
export function toggleClass(element: Element, className: string): void {
  element.classList.toggle(className);
}

// Other exported functions for toggling attributes, properties, etc.

This approach ensures that when the compiler generates an import { toggleClass } from '@hyperscript/runtime', a bundler can resolve this to a single, tiny function, leaving the code for all other commands (like fetch, wait, or add) out of the final bundle.
The js command, which allows embedding raw JavaScript, presents a unique challenge as it is an escape hatch that breaks static analysis. The new compiler will handle this gracefully. It will treat the body of the js block as an opaque string but will parse the parameter list (e.g., js(var1, var2)) to identify its dependencies on hyperscript variables. During code generation, it will create a JavaScript function that accepts these variables as arguments and contains the user's raw JavaScript as its body. This isolates the "unsafe" code within a predictable function scope, allowing the compiler to manage the surrounding hyperscript logic and data flow while preserving this powerful feature.
hyperscript.org Feature-to-Module Mapping
The following table provides a concrete illustration of how the existing language features will be mapped to the proposed modular runtime structure. This serves as a high-level implementation guide and demonstrates the granular nature of the new library.
| Hyperscript Feature | TypeScript Module Export (Conceptual) |
|---|---|
| command add.myClass | import { addClass } from '@hyperscript/runtime/commands/add'; |
| command fetch /example | import { fetch } from '@hyperscript/runtime/commands/fetch'; |
| command wait 2s | import { wait } from '@hyperscript/runtime/commands/wait'; |
| command transition opacity | import { transition } from '@hyperscript/runtime/commands/transition'; |
| expression.class | import { queryClass } from '@hyperscript/runtime/expressions/query'; |
| expression #id | import { queryId } from '@hyperscript/runtime/expressions/query'; |
| expression me | import { me } from '@hyperscript/runtime/expressions/relative'; |
| feature on <event> | import { on } from '@hyperscript/runtime/features/on'; |
| feature behavior <name> | import { installBehavior } from '@hyperscript/runtime/features/behavior'; |
Achieving Optimal Performance and Bundle Size
Build Tooling: A High-Performance Toolchain with esbuild
To ensure the hyperscript compiler and the entire build process are exceptionally fast, the toolchain should be built upon esbuild. esbuild is a next-generation JavaScript bundler and minifier written in Go, which allows it to perform orders of magnitude faster than traditional JavaScript-based tools. This speed is not merely a convenience; it is critical to upholding the hyperscript philosophy of a simple and immediate developer experience. A build step that feels instantaneous is the key to convincing users accustomed to a "no build step" workflow of the benefits of compilation. While Rollup pioneered the concept of tree-shaking , esbuild now provides a mature, high-performance implementation of all necessary features, including tree-shaking, minification, and code-splitting, making it the ideal foundation for the new hyperscript toolchain.
Advanced Tree-Shaking for a Minimalist Runtime
Achieving the smallest possible bundle size requires a rigorous and principled approach to authoring the modular runtime library. Several key techniques will be employed.
 * ESM as a Non-Negotiable Foundation: The entire @hyperscript/runtime package will be authored and distributed as ES Modules (ESM). ESM's static import and export syntax is the fundamental requirement for static analysis, which allows bundlers to determine which code is unused. The package's package.json file will use the "module" field to explicitly point to the ESM entry point, signaling to modern bundlers that a tree-shakable version of the library is available.
 * Managing Side Effects: A side effect is any code that performs an action affecting a shared or global state merely by being imported, such as modifying the window object or injecting a stylesheet. Such code is "impure" and cannot be safely removed by a bundler, even if none of its exports are used. The @hyperscript/runtime library will be meticulously designed to be free of side effects. To formally declare this purity to the ecosystem, its package.json will contain the "sideEffects": false property. This is a powerful hint to bundlers like esbuild and webpack that they can aggressively prune any module from the library that is not explicitly imported.
 * The /*#__PURE__*/ Annotation: In some cases, a function call might appear to have side effects to a minifier, even if it doesn't. A common example is a higher-order function that creates and returns another function. To prevent such code from breaking tree-shaking, the /*#__PURE__*/ annotation will be used. This comment explicitly tells the minifier (such as esbuild's internal minifier or Terser) that the function call has no side effects and can be safely removed if its return value is unused.
 * Avoiding Un-shakable Patterns: The runtime library's API design will strictly avoid patterns known to be hostile to tree-shaking. This includes exporting large objects or classes with multiple methods. Bundlers cannot safely remove individual methods from a class or properties from an object, so if any part of the class or object is used, the entire thing must be included in the bundle. In particular, static class methods have proven to be difficult for tools like Rollup to tree-shake effectively. Therefore, the runtime will exclusively export small, atomic, standalone functions.
Generating JIT-Friendly JavaScript
The ultimate goal of the compiler is not just to produce correct JavaScript, but to produce JavaScript that is highly optimizable by modern JIT compilers, particularly V8. The code generator will be designed to produce simple, predictable, and monomorphic code that V8's tiered compilation pipeline can process efficiently.
 * Stable Object Shapes (Hidden Classes): V8 achieves high performance for object property access by creating "hidden classes" (or "shapes") internally. If objects maintain a consistent structure, V8 can generate highly optimized machine code. However, if properties are added or deleted dynamically, it forces a change in the hidden class, which can trigger costly deoptimization. The generated code and the internal workings of the runtime will ensure that any internal objects used within performance-sensitive code paths are initialized with a consistent shape and are not altered dynamically.
 * Monomorphic Call Sites: When a function is consistently called with the same types of arguments, the call site is considered "monomorphic," which is the fastest path for a JIT compiler. If the types vary ("polymorphic") or are highly unpredictable ("megamorphic"), the engine must add checks and cannot optimize as aggressively. The hyperscript compiler will generate direct, explicit calls to the imported runtime functions (e.g., toggleClass(element, 'red')). This is vastly superior to a more dynamic approach like runtime[command](...), which would create polymorphic or megamorphic call sites that are much harder for the JIT to optimize.
 * Leveraging Modern V8 Tiers (Maglev): V8's modern architecture features a multi-tiered compilation system: the Ignition interpreter for fast startup, the Sparkplug baseline compiler, the new Maglev mid-tier optimizing compiler, and the TurboFan peak-performance optimizing compiler. By generating straightforward, predictable code, the hyperscript compiler enables the new, faster Maglev compiler to quickly produce highly optimized machine code. This provides significant performance gains without the longer "warm-up" time and higher compilation cost associated with the more complex TurboFan compiler, leading to better real-world application responsiveness.
This combination of a build-time compiler and a tree-shakable runtime creates a virtuous cycle of optimization. The hyperscript compiler performs the first stage of optimization at the language level, analyzing the hyperscript code and generating a clean JavaScript module with an explicit dependency graph. This module is perfectly structured for the second stage of optimization: a highly effective tree-shaking pass by a bundler like esbuild. The bundler does not need to understand the complexities of hyperscript; it simply sees a well-formed ES module free of dynamic imports and side effects. This two-stage process ensures that optimizations are applied at both the language and module levels, resulting in a final bundle that is smaller and more performant than either stage could achieve alone.
Implementation Roadmap and Strategic Recommendations
Phased Implementation Plan
A phased, iterative approach is recommended for developing and releasing the new architecture. This strategy will allow for incremental value delivery, community feedback, and risk mitigation throughout the process.
 * Phase 1: The Modular TypeScript Runtime (@hyperscript/runtime)
   * Objective: Create the foundational, tree-shakable library.
   * Tasks:
     * Initiate a new monorepo using pnpm workspaces.
     * Rewrite the entire existing JavaScript codebase into a fully typed, modular TypeScript library within the @hyperscript/runtime package.
     * Deconstruct the current monolithic runtime object into individual, named function exports for every command and expression, ensuring each function is pure and side-effect-free.
     * Establish a comprehensive test suite using a modern framework like Jest or Vitest to ensure correctness and prevent regressions.
     * Configure the build process (using esbuild or tsup) to output both ESM and CJS formats and to generate accurate TypeScript declaration files (.d.ts).
     * Publish this package to npm.
   * Outcome: This phase provides immediate value to existing hyperscript users who already incorporate a build step into their projects. They can begin using the modular runtime to achieve smaller bundle sizes without waiting for the full compiler.
 * Phase 2: The Compiler Core (Parser & Analyzer)
   * Objective: Build the "brain" of the compiler.
   * Tasks:
     * Develop the hyperscript language parser within the @hyperscript/compiler package. This involves defining the language grammar and implementing a parser that converts hyperscript strings into a well-defined AST.
     * Build the static analyzer to traverse the AST. This component will be responsible for identifying all used commands and expressions, resolving symbols like me and it, and constructing a complete dependency graph for each script.
   * Outcome: A functional core compiler capable of understanding and analyzing hyperscript code, ready for the code generation phase.
 * Phase 3: Code Generation and Bundling
   * Objective: Complete the compiler by enabling it to produce executable code.
   * Tasks:
     * Implement the code generator, which will take the analyzed AST and its dependency graph and translate them into an optimized, tree-shakable JavaScript module string.
     * Integrate esbuild's programmatic API to take this generated module string, bundle it with the required functions from @hyperscript/runtime, and produce a final, minified output file.
   * Outcome: A complete, end-to-end compilation pipeline that can transform an HTML file with hyperscript into a highly optimized JavaScript bundle.
 * Phase 4: Developer Experience and Tooling
   * Objective: Make the compiler easy and intuitive to use for all developers.
   * Tasks:
     * Develop the @hyperscript/cli tool, providing a simple command-line interface for compiling projects.
     * Create the @hyperscript/vite-plugin for seamless, zero-config integration into the popular Vite ecosystem.
     * Thoroughly update the hyperscript.org documentation with migration guides, tutorials for the new compiled approach, and clear best practices.
     * (Optional but recommended) Develop a Language Server Protocol (LSP) implementation for hyperscript. This would enable rich IDE support, such as syntax highlighting, autocompletion, and real-time error checking for hyperscript code directly within HTML _ attributes in editors like VS Code.
Strategic Recommendations for Adoption and Community
 * Backward Compatibility: To ensure a smooth transition for the existing user base, the project should provide a "legacy" build. This build would bundle the entire modular runtime and expose the same global _hyperscript object that users are familiar with. This offers a non-breaking upgrade path for those who cannot or do not wish to adopt a build step immediately, preventing a fracture in the community.
 * Clear Communication: The introduction of a compiler should be framed carefully. It is not an added complexity but an optional, powerful tool for production optimization. The marketing and documentation should emphasize the "zero-config" nature of the new tooling and highlight the concrete benefits: dramatically smaller bundles and faster applications. The message should be one of empowerment, not of added burden.
 * Synergy with htmx: Hyperscript's relationship with htmx is a significant strategic asset. The project should work closely with the htmx development team to ensure that the new compiled hyperscript integrates flawlessly. The combination of htmx for elegant server interactions and a compiled, optimized hyperscript for client-side logic creates a compelling, modern, and high-performance stack that offers a powerful alternative to complex SPA frameworks.
Future Vision: Beyond the Compiler
The creation of a formal compiler and AST opens up numerous possibilities for the future of the hyperscript language and its ecosystem.
 * Static Site Generation (SSG): The compiler could be integrated into SSG frameworks. It could analyze init blocks and, where possible, pre-execute them at build time to render the initial state directly into the static HTML, further improving perceived performance.
 * WebAssembly (WASM): For future performance-critical features, the modular runtime provides an avenue for exploration with WebAssembly. Certain computationally intensive utility functions could potentially be rewritten in a language like Rust and compiled to WASM for near-native execution speed.
 * Structured Language Evolution: Perhaps most importantly, having a formal parser and AST provides a robust foundation for the future of the hyperscript language itself. Proposing, debating, and implementing new language features becomes a more structured and less error-prone process when built upon a formal language specification, ensuring that hyperscript can continue to evolve and adapt for years to come.
