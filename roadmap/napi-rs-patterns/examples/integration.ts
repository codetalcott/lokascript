/**
 * Example: Integrating native tokenizer with HyperFixi
 *
 * This shows how the JavaScript/TypeScript layer would integrate with
 * the native Rust tokenizer via napi-rs bindings.
 */

// Type definitions auto-generated by napi-rs from Rust code
interface Token {
  kind: TokenKind;
  value: string;
  start: number;
  end: number;
  line: number;
  column: number;
}

type TokenKind =
  | 'Number'
  | 'String'
  | 'Boolean'
  | 'Identifier'
  | 'Keyword'
  | 'Operator'
  | 'ComparisonOp'
  | 'LogicalOp'
  | 'ArithmeticOp'
  | 'OpenParen'
  | 'CloseParen'
  | 'OpenBrace'
  | 'CloseBrace'
  | 'OpenBracket'
  | 'CloseBracket'
  | 'Comma'
  | 'Dot'
  | 'Colon'
  | 'Semicolon'
  | 'AttributeRef'
  | 'IdRef'
  | 'ClassRef'
  | 'Whitespace'
  | 'Newline'
  | 'Comment'
  | 'EOF'
  | 'Unknown';

// Native binding interface (generated by napi-rs)
interface NativeBinding {
  tokenize(source: string): Token[];
  isKeyword(word: string): boolean;

  // Class-based tokenizer for streaming
  NativeTokenizer: {
    new (source: string): NativeTokenizer;
  };
}

interface NativeTokenizer {
  tokenizeAll(): Token[];
  nextToken(): Token;
  position(): { offset: number; line: number; column: number };
}

// =============================================================================
// Hybrid Loader Pattern
// =============================================================================

let nativeBinding: NativeBinding | null = null;
let loadAttempted = false;

/**
 * Attempt to load native bindings with graceful fallback
 */
async function loadNativeBinding(): Promise<NativeBinding | null> {
  if (loadAttempted) return nativeBinding;
  loadAttempted = true;

  // Environment detection
  const isNode =
    typeof process !== 'undefined' && process.versions?.node !== undefined;
  const isBrowser = typeof window !== 'undefined';

  if (isNode) {
    try {
      // Platform-specific native binary loading
      // napi-rs handles platform detection automatically
      const binding = await import('@hyperfixi/native-core');
      nativeBinding = binding as unknown as NativeBinding;
      console.debug('[HyperFixi] Native tokenizer loaded successfully');
    } catch (error) {
      console.debug('[HyperFixi] Native tokenizer unavailable, using JS fallback');
    }
  } else if (isBrowser) {
    try {
      // Load WASM version for browsers
      const wasm = await import('@hyperfixi/native-core/wasm');
      await wasm.default(); // Initialize WASM module
      nativeBinding = wasm as unknown as NativeBinding;
      console.debug('[HyperFixi] WASM tokenizer loaded successfully');
    } catch (error) {
      console.debug('[HyperFixi] WASM tokenizer unavailable, using JS fallback');
    }
  }

  return nativeBinding;
}

// =============================================================================
// JavaScript Fallback Tokenizer (simplified)
// =============================================================================

function jsTokenize(source: string): Token[] {
  // Simplified JavaScript tokenizer (actual implementation would be more complete)
  const tokens: Token[] = [];
  let pos = 0;
  let line = 1;
  let column = 1;

  while (pos < source.length) {
    const char = source[pos];

    // Skip whitespace
    if (/\s/.test(char)) {
      if (char === '\n') {
        line++;
        column = 1;
      } else {
        column++;
      }
      pos++;
      continue;
    }

    // Simple identifier/keyword matching
    if (/[a-zA-Z_]/.test(char)) {
      const start = pos;
      const startColumn = column;
      while (pos < source.length && /[a-zA-Z0-9_-]/.test(source[pos])) {
        pos++;
        column++;
      }
      const value = source.slice(start, pos);
      const isKw = isKeywordJS(value);
      tokens.push({
        kind: isKw ? 'Keyword' : 'Identifier',
        value,
        start,
        end: pos,
        line,
        column: startColumn,
      });
      continue;
    }

    // Numbers
    if (/[0-9]/.test(char)) {
      const start = pos;
      const startColumn = column;
      while (pos < source.length && /[0-9.]/.test(source[pos])) {
        pos++;
        column++;
      }
      // Check for time units
      if (pos < source.length && /[msh]/.test(source[pos])) {
        pos++;
        column++;
        if (source[pos] === 's') {
          pos++;
          column++;
        }
      }
      tokens.push({
        kind: 'Number',
        value: source.slice(start, pos),
        start,
        end: pos,
        line,
        column: startColumn,
      });
      continue;
    }

    // Default: advance and mark unknown
    tokens.push({
      kind: 'Unknown',
      value: char,
      start: pos,
      end: pos + 1,
      line,
      column,
    });
    pos++;
    column++;
  }

  tokens.push({
    kind: 'EOF',
    value: '',
    start: pos,
    end: pos,
    line,
    column,
  });

  return tokens;
}

function isKeywordJS(word: string): boolean {
  const keywords = new Set([
    'if',
    'else',
    'then',
    'end',
    'repeat',
    'for',
    'while',
    'until',
    'set',
    'get',
    'put',
    'add',
    'remove',
    'toggle',
    'hide',
    'show',
    'wait',
    'send',
    'trigger',
    'me',
    'my',
    'you',
    'your',
    'it',
    'its',
    'to',
    'into',
    'from',
    'at',
    'in',
    'of',
    'on',
    'with',
    'as',
    'and',
    'or',
    'not',
    'is',
    'true',
    'false',
  ]);
  return keywords.has(word);
}

// =============================================================================
// Unified Tokenizer API
// =============================================================================

/**
 * Tokenize hyperscript source code.
 * Automatically uses native implementation when available.
 */
export async function tokenize(source: string): Promise<Token[]> {
  const native = await loadNativeBinding();
  if (native) {
    return native.tokenize(source);
  }
  return jsTokenize(source);
}

/**
 * Synchronous tokenization (use with caution in async contexts)
 */
export function tokenizeSync(source: string): Token[] {
  if (nativeBinding) {
    return nativeBinding.tokenize(source);
  }
  return jsTokenize(source);
}

/**
 * Create a streaming tokenizer for large inputs
 */
export async function createTokenizer(
  source: string
): Promise<TokenizerInterface> {
  const native = await loadNativeBinding();
  if (native) {
    return new NativeTokenizerWrapper(new native.NativeTokenizer(source));
  }
  return new JSTokenizerWrapper(source);
}

// Tokenizer interface for streaming
interface TokenizerInterface {
  next(): Token;
  all(): Token[];
  position(): { offset: number; line: number; column: number };
}

class NativeTokenizerWrapper implements TokenizerInterface {
  constructor(private tokenizer: NativeTokenizer) {}

  next(): Token {
    return this.tokenizer.nextToken();
  }

  all(): Token[] {
    return this.tokenizer.tokenizeAll();
  }

  position() {
    return this.tokenizer.position();
  }
}

class JSTokenizerWrapper implements TokenizerInterface {
  private tokens: Token[];
  private current = 0;

  constructor(source: string) {
    this.tokens = jsTokenize(source);
  }

  next(): Token {
    return this.tokens[this.current++] ?? this.tokens[this.tokens.length - 1];
  }

  all(): Token[] {
    return this.tokens;
  }

  position() {
    const token = this.tokens[this.current] ?? this.tokens[this.tokens.length - 1];
    return {
      offset: token.start,
      line: token.line,
      column: token.column,
    };
  }
}

// =============================================================================
// Performance Monitoring
// =============================================================================

interface TokenizeMetrics {
  source_length: number;
  token_count: number;
  duration_ms: number;
  native: boolean;
}

/**
 * Tokenize with performance metrics
 */
export async function tokenizeWithMetrics(
  source: string
): Promise<{ tokens: Token[]; metrics: TokenizeMetrics }> {
  const start = performance.now();
  const native = await loadNativeBinding();
  const tokens = native ? native.tokenize(source) : jsTokenize(source);
  const duration_ms = performance.now() - start;

  return {
    tokens,
    metrics: {
      source_length: source.length,
      token_count: tokens.length,
      duration_ms,
      native: !!native,
    },
  };
}

// =============================================================================
// Usage Examples
// =============================================================================

async function examples() {
  // Basic tokenization
  const tokens = await tokenize('on click set my.value to 5');
  console.log('Tokens:', tokens);

  // With metrics
  const { tokens: t, metrics } = await tokenizeWithMetrics(`
    on click
      set counter to counter + 1
      put counter into #display
    end
  `);
  console.log(`Tokenized ${metrics.source_length} chars in ${metrics.duration_ms.toFixed(2)}ms`);
  console.log(`Using ${metrics.native ? 'native' : 'JavaScript'} tokenizer`);

  // Streaming for large inputs
  const tokenizer = await createTokenizer(largeHyperscriptSource);
  let token: Token;
  while ((token = tokenizer.next()).kind !== 'EOF') {
    // Process tokens one at a time
    console.log(token);
  }
}

const largeHyperscriptSource = `
  behavior Draggable
    on mousedown
      set dragging to true
      set startX to event.clientX
      set startY to event.clientY
    end

    on mousemove
      if dragging
        set dx to event.clientX - startX
        set dy to event.clientY - startY
        add { transform: translate(\${dx}px, \${dy}px) } to me
      end
    end

    on mouseup
      set dragging to false
    end
  end
`;
